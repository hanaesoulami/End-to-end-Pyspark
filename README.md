# Projet End-to-End PySpark

Dans ce projet end-to-end en PySpark, j’ai mis en place **un pipeline de traitement de données** autour d’un dataset de **vols aériens**.
À travers l’utilisation des **DataFrames Spark**, j’ai réalisé plusieurs étapes clés du **data engineering** : sélection et filtrage de colonnes, création de nouvelles variables (comme la vitesse moyenne), et conversion de types de données pour permettre des analyses numériques.
Ce travail m’a permis de me familiariser avec les opérations fondamentales de transformation de données à grande échelle. 
Bien qu’un obstacle ait été rencontré lors du nettoyage de données mal formées (valeurs 'NA' dans des colonnes numériques), ce projet illustre ma capacité à structurer un traitement analytique en environnement distribué, et il constitue une étape importante dans la constitution de mon portfolio en data engineering.
